# Fabric Inspection Chatbot

## ğŸ“Œ Project Overview
This project is a chatbot designed to assist with fabric inspection tasks. It integrates **Groq** for language processing and **Pinecone** for vector storage, making it efficient for retrieving relevant information based on fabric-related queries.

## ğŸš€ Features
- **Natural Language Processing**: Uses `deepseek-r1-distill-llama-70b` for text understanding.
- **Embeddings with Llama 3.2**: Enhances search performance.
- **Vector Database**: Utilizes `Pinecone` for fast and scalable search.
- **Environment Variables**: API keys and other configurations are securely stored in a `.env` file.

## ğŸ› ï¸ Installation
### **1ï¸âƒ£ Clone the Repository**
```bash
git clone https://github.com/yourusername/fabric-inspection-chatbot.git
cd fabric-inspection-chatbot
```

### **2ï¸âƒ£ Install Dependencies**
```bash
pip install -r requirements.txt
```

### **3ï¸âƒ£ Set Up Environment Variables**
Create a `.env` file and add your API keys:
```env
GROQ_API_KEY="your_groq_api_key"
PINECONE_API_KEY="your_pinecone_api_key"
PINECONE_INDEX="your_index_name"
PINECONE_ENV="us-east-1"
```

### **4ï¸âƒ£ Run the Application**
```bash
python app.py
```

## ğŸ› ï¸ Usage
- Upload fabric images.
- Chat with the bot to get fabric analysis.
- Retrieve past inspections from Pinecone.

## âš™ï¸ Configuration
Modify `config.py` to adjust settings like model type, embedding parameters, and vector search preferences.

## ğŸ—ï¸ Project Structure
```
ğŸ“‚ fabric-inspection-chatbot
â”‚-- ğŸ“‚ models
â”‚-- ğŸ“‚ utils
â”‚-- app.py
â”‚-- requirements.txt
â”‚-- .env
â”‚-- README.md
```

## ğŸ“ License
This project is open-source and available under the MIT License.

## ğŸ¤ Contributing
Pull requests are welcome! Please follow best coding practices and ensure proper documentation.

